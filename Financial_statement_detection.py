import io

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.ensemble import IsolationForest

st.set_page_config(
    page_title="íšŒê³„ ì´ìƒ íƒì§€ ëŒ€ì‹œë³´ë“œ Â· ê°•í™”íŒ",
    layout="wide",
)


def reset_session_for_new_file(filename: str):
    st.session_state["uploaded_name"] = filename
    st.session_state["base_top_ids"] = None
    st.session_state["base_params"] = None


def _ensure_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    aliases = {
        "company": ["company", "íšŒì‚¬ëª…", "ë²•ì¸ëª…"],
        "year": ["year", "ê²°ì‚°ì—°ë„", "ì—°ë„"],
        "industry": ["industry", "ì—…ì¢…","ì‚°ì—…"],
        "sales": ["sales", "ë§¤ì¶œì•¡", "ìˆ˜ìµ"],
        "ar": ["ar", "accounts_receivable", "ë§¤ì¶œì±„ê¶Œ"],
        "inventory": ["inventory", "ì¬ê³ ìì‚°"],
        "total_assets": ["total_assets", "ìì‚°ì´ê³„", "ì´ìì‚°"],
        "ocf": ["ocf", "ì˜ì—…í™œë™í˜„ê¸ˆíë¦„", "ì˜ì—…í˜„ê¸ˆíë¦„"],
        "net_income": ["net_income", "ë‹¹ê¸°ìˆœì´ìµ"],
    }

    col_map = {}
    for canonical, cands in aliases.items():
        for c in cands:
            if c in df.columns:
                col_map[c] = canonical
                break

    df = df.rename(columns=col_map)

    required = [
        "company",
        "year",
        "sales",
        "ar",
        "inventory",
        "total_assets",
        "ocf",
        "net_income",
    ]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(
            f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing}. "
            f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}"
        )

    if "industry" not in df.columns:
        df["industry"] = "ë¯¸ì§€ì •"

    return df


def _compute_benford_for_dataset(df: pd.DataFrame) -> dict:
    vals = df["sales"].astype(float).abs()
    vals = vals[vals > 0]

    if len(vals) == 0:
        return {
            "obs": None,
            "exp": None,
            "mad": None,
            "n": 0,
            "span": 0.0,
            "applicable": False,
            "reason": "ë§¤ì¶œ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.",
        }

    first_digits = []
    for v in vals:
        s = str(int(round(v)))
        s = s.lstrip("0")
        if not s:
            continue
        d = s[0]
        if d in "123456789":
            first_digits.append(int(d))

    n = len(first_digits)
    if n == 0:
        return {
            "obs": None,
            "exp": None,
            "mad": None,
            "n": 0,
            "span": float(vals.max() / max(vals.min(), 1e-9)),
            "applicable": False,
            "reason": "ì„ ë‘ ìë¦¿ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
        }

    counts = pd.value_counts(first_digits).reindex(range(1, 10), fill_value=0)
    obs = (counts / counts.sum()).values

    digits = np.arange(1, 10)
    exp = np.log10(1 + 1 / digits)

    mad = float(np.mean(np.abs(obs - exp)))
    span = float(vals.max() / max(vals.min(), 1e-9))

    applicable = True
    reason = "ê¸°ë³¸ í‘œë³¸/ë²”ìœ„ ê¸°ì¤€ì„ ì¶©ì¡±í•©ë‹ˆë‹¤."
    if n < 100:
        applicable = False
        reason = f"í‘œë³¸ ìˆ˜(n={n})ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤(ê¶Œì¥ 100ê°œ ì´ìƒ)."
    elif span < 100:
        applicable = False
        reason = f"ê¸ˆì•¡ ë²”ìœ„ê°€ ì¢ìŠµë‹ˆë‹¤(ìµœëŒ€/ìµœì†Œ ë¹„ìœ¨â‰ˆ{span:.1f}, ê¶Œì¥ â‰¥ 100)."

    return {
        "obs": obs.tolist(),
        "exp": exp.tolist(),
        "mad": mad,
        "n": n,
        "span": span,
        "applicable": applicable,
        "reason": reason,
    }


def run_pipeline(
    df_raw: pd.DataFrame,
    group_mode: str = "year_industry",
    contamination: float = 0.10,
    w_beneish: float = 1.0,
    w_iso: float = 1.0,
    w_benford: float = 1.0,
):
    df = _ensure_columns(df_raw)

    for col in ["sales", "ar", "inventory", "total_assets", "ocf", "net_income"]:
        s = df[col].astype(str)
        s = s.str.replace(",", "", regex=False)
        s = s.str.replace(" ", "", regex=False)
        s = s.str.replace("\u00a0", "", regex=False)
        df[col] = pd.to_numeric(s, errors="coerce")

    df = df.reset_index(drop=True)
    df["row_id"] = df.index + 1

    df["year"] = pd.to_numeric(df["year"], errors="coerce")

    eps = 1e-9

    df["ar_to_sales"] = df["ar"] / (df["sales"] + eps)
    df["inv_to_sales"] = df["inventory"] / (df["sales"] + eps)
    df["ocf_to_ni"] = df["ocf"] / (df["net_income"] + eps)
    df["tata"] = (df["net_income"] - df["ocf"]) / (df["total_assets"] + eps)


    df = df.sort_values(["company", "year"])
    df["sales_yoy"] = (
        df.groupby("company")["sales"].pct_change().fillna(0.0) * 100.0
    )

    metrics = ["ar_to_sales", "inv_to_sales", "tata", "ocf_to_ni"]

    def zscore_group(g: pd.DataFrame, cols: list):
        g = g.copy()
        for c in cols:
            col_name = str(c)
            m = g[col_name].mean()
            s = g[col_name].std(ddof=0)
            if s is None or s == 0 or np.isnan(s):
                g[col_name + "_z"] = 0.0
            else:
                g[col_name + "_z"] = (g[col_name] - m) / s
        return g

    if group_mode == "year":
        df = df.groupby("year", group_keys=False).apply(zscore_group, cols=metrics)
    elif group_mode == "year_industry":
        df = (
            df.groupby(["year", "industry"], group_keys=False)
            .apply(zscore_group, cols=metrics)
        )
    else:
        df = zscore_group(df, metrics)

    z_ar = df.get("ar_to_sales_z", pd.Series(0, index=df.index))
    z_inv = df.get("inv_to_sales_z", pd.Series(0, index=df.index))
    z_tata = df.get("tata_z", pd.Series(0, index=df.index))
    z_ocf = df.get("ocf_to_ni_z", pd.Series(0, index=df.index))

    df["mscore_raw"] = z_ar + z_inv + z_tata - z_ocf

    iso_features = ["ar_to_sales", "inv_to_sales", "tata", "ocf_to_ni"]
    X = df[iso_features].fillna(0.0).values

    try:
        iso = IsolationForest(
            contamination=contamination,
            random_state=42,
        )
        iso.fit(X)
        iso_raw = -iso.decision_function(X)
        iso_raw = np.array(iso_raw)
        iso_norm = (iso_raw - iso_raw.min()) / (iso_raw.max() - iso_raw.min() + eps)
    except Exception:
        iso_norm = np.zeros(df.shape[0])

    df["iso_score"] = iso_norm

    benford_info = _compute_benford_for_dataset(df)
    benford_applicable = benford_info["applicable"]
    benford_reason = benford_info["reason"]
    benford_overall = {
        "obs": benford_info["obs"],
        "exp": benford_info["exp"],
        "mad": benford_info["mad"],
    }

    if benford_info["mad"] is not None:
        df["benford_mad"] = float(benford_info["mad"])
    else:
        df["benford_mad"] = np.nan

    m = df["mscore_raw"].fillna(0.0).values
    m_norm = (m - m.min()) / (m.max() - m.min() + eps)

    ben_used = bool(
        benford_applicable and w_benford > 0 and benford_info["mad"] is not None
    )
    if ben_used:
        b = df["benford_mad"].fillna(0.0).values
        b_norm = (b - b.min()) / (b.max() - b.min() + eps)
    else:
        b_norm = np.zeros(df.shape[0])

    flag_score = (
        w_beneish * m_norm
        + w_iso * df["iso_score"].values
        + w_benford * b_norm
    )

    df["flag_score"] = flag_score

    df_scored = df.sort_values("flag_score", ascending=False).reset_index(drop=True)
    df_scored["rank"] = np.arange(1, len(df_scored) + 1)

    meta = {
        "benford_applicable": benford_applicable,
        "benford_reason": benford_reason,
        "benford_overall": benford_overall,
        "benford_n": benford_info["n"],
        "benford_span": benford_info["span"],
        "benford_used_in_score": ben_used,
    }

    return df_scored, meta


st.sidebar.header("ì˜µì…˜")

group_mode = st.sidebar.radio(
    "ê·¸ë£¹ í‘œì¤€í™” ê¸°ì¤€",
    ["ì—°ë„", "ì—°ë„+ì‚°ì—…", "ì „ì²´"],
    help="ì—°ë„/ì‚°ì—…ë³„ë¡œ ì§€í‘œë¥¼ í‘œì¤€í™”í•´ ì—…ì¢…Â·ê·œëª¨ ì°¨ì´ì—ì„œ ì˜¤ëŠ” ì™œê³¡ì„ ì¤„ì…ë‹ˆë‹¤.",
)

if group_mode == "ì—°ë„":
    group_mode_key = "year"
elif group_mode == "ì—°ë„+ì‚°ì—…":
    group_mode_key = "year_industry"
else:
    group_mode_key = "all"

contamination = st.sidebar.slider(
    "íƒì§€ ë¯¼ê°ë„(ì˜ì‹¬ ë¹„ìœ¨, ISO contamination)",
    min_value=0.01,
    max_value=0.30,
    value=0.10,
    step=0.01,
    help="Isolation Forestì—ì„œ ì´ìƒì¹˜ë¡œ ë³¼ ë¹„ìœ¨ì…ë‹ˆë‹¤. ë†’ì¼ìˆ˜ë¡ ë” ë§ì€ íšŒì‚¬ë¥¼ ì˜ì‹¬ìœ¼ë¡œ ì¡ìŠµë‹ˆë‹¤.",
)

top_n = st.sidebar.slider(
    "Top-N(ì˜ì‹¬ í›„ë³´ ìˆ˜)",
    min_value=3,
    max_value=30,
    value=10,
    step=1,
)

st.sidebar.markdown("---")
st.sidebar.markdown("**ê°€ì¤‘ì¹˜ ì„¤ì •**")

w_beneish = st.sidebar.slider(
    "Beneish ë¹„ì¤‘",
    min_value=0.0,
    max_value=3.0,
    value=1.0,
    step=0.1,
)
w_iso = st.sidebar.slider(
    "Isolation Forest ë¹„ì¤‘",
    min_value=0.0,
    max_value=3.0,
    value=1.0,
    step=0.1,
)
w_benford = st.sidebar.slider(
    "Benford ë¹„ì¤‘",
    min_value=0.0,
    max_value=3.0,
    value=1.0,
    step=0.1,
)

st.sidebar.markdown("---")
st.sidebar.info(
    "ğŸ“ í•„ìˆ˜ í•­ëª©: íšŒì‚¬ëª…, ê²°ì‚°ì—°ë„, ë§¤ì¶œì•¡, ë§¤ì¶œì›ê°€, íŒë§¤ê´€ë¦¬ë¹„, ì˜ì—…ì´ìµ, ê°ê°€ìƒê°ë¹„, "
    "ë§¤ì¶œì±„ê¶Œ, ì¬ê³ ìì‚°, ìì‚°ì´ê³„, ë¶€ì±„ì´ê³„, ì˜ì—…í™œë™í˜„ê¸ˆíë¦„, ë‹¹ê¸°ìˆœì´ìµ, ì—…ì¢…(ê¶Œì¥)"
)

st.title("íšŒê³„ ì´ìƒ íƒì§€ ëŒ€ì‹œë³´ë“œ Â· ê°•í™”íŒ")

st.markdown(
    """
1. ì•„ë˜ì— CSV/ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.  
2. í•„ìˆ˜ í•­ëª©ì´ ë“¤ì–´ìˆì–´ì•¼ í•©ë‹ˆë‹¤.  
3. ì™¼ìª½ì—ì„œ **íƒì§€ ë¯¼ê°ë„(ì˜ì‹¬ ë¹„ìœ¨)**ì™€ **ê°€ì¤‘ì¹˜**ë¥¼ ì¡°ì •í•˜ë©° Top-N ë³€í™”ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  
4. í•˜ë‹¨ íƒ­ì—ì„œ  
   - ğŸ” **Top-N ì˜ì‹¬ ë¦¬ìŠ¤íŠ¸ & ì¼ê´€ ì˜ì‹¬ ê¸°ì—…**,  
   - ğŸŒ¡ï¸ **ë™ì¢… ê·¸ë£¹ ì—´ì§€ë„(ë¹„ìŠ·í•œ íšŒì‚¬ë¼ë¦¬ ë¹„êµ)**,  
   - ğŸ“Š **Benford ì‚¬ìš© ê°€ëŠ¥ì„± ì§„ë‹¨**  
   ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
)

uploaded = st.file_uploader("CSV ë˜ëŠ” Excel ì—…ë¡œë“œ", type=["csv", "xlsx"])

if uploaded is None:
    st.stop()

if "uploaded_name" not in st.session_state or st.session_state["uploaded_name"] != uploaded.name:
    reset_session_for_new_file(uploaded.name)

if uploaded.name.lower().endswith(".csv"):
    df_raw = pd.read_csv(uploaded)
else:
    df_raw = pd.read_excel(uploaded)

st.caption(f"ì—…ë¡œë“œëœ ë°ì´í„° í¬ê¸°: {df_raw.shape[0]}í–‰ Ã— {df_raw.shape[1]}ì—´")
with st.expander("ì›ë³¸ ì¼ë¶€ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
    st.dataframe(df_raw.head())

try:
    df_scored, meta = run_pipeline(
        df_raw,
        group_mode=group_mode_key,
        contamination=contamination,
        w_beneish=w_beneish,
        w_iso=w_iso,
        w_benford=w_benford,
    )
except Exception as e:
    st.error(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

df_top = df_scored.head(top_n).copy()

base_params = {
    "group_mode": group_mode_key,
    "contamination": 0.10,
    "w_beneish": 1.0,
    "w_iso": 1.0,
    "w_benford": 1.0,
}

if st.session_state.get("base_top_ids") is None:
    base_df, _ = run_pipeline(
        df_raw,
        group_mode=base_params["group_mode"],
        contamination=base_params["contamination"],
        w_beneish=base_params["w_beneish"],
        w_iso=base_params["w_iso"],
        w_benford=base_params["w_benford"],
    )
    base_top = base_df.head(top_n).copy()
    st.session_state["base_top_ids"] = set(base_top["row_id"].tolist())
    st.session_state["base_params"] = base_params

current_ids = set(df_top["row_id"].tolist())
stable_ids = current_ids.intersection(st.session_state["base_top_ids"])
stable_df = df_top[df_top["row_id"].isin(stable_ids)].copy()

tab1, tab2, tab3 = st.tabs(
    ["ğŸ” Top-N & ì¼ê´€ ì˜ì‹¬ ê¸°ì—…", "ğŸŒ¡ï¸ ë™ì¢… ê·¸ë£¹ ì—´ì§€ë„", "ğŸ“Š Benford ì§„ë‹¨"]
)

with tab1:
    st.subheader("ì˜ì‹¬ í›„ë³´ Top-N")

    show_cols = [
        "rank",
        "company",
        "year",
        "industry",
        "flag_score",
        "mscore_raw",
        "iso_score",
        "benford_mad",
        "ar_to_sales",
        "inv_to_sales",
        "ocf_to_ni",
    ]
    show_cols = [c for c in show_cols if c in df_top.columns]

    st.dataframe(
        df_top[show_cols],
        use_container_width=True,
        height=360,
    )

    st.markdown("---")
    st.markdown("#### ğŸ¯ ì„¤ì •ì„ ë°”ê¿”ë„ ê³„ì† ë‚¨ëŠ” â€˜ì¼ê´€ ì˜ì‹¬ ê¸°ì—…â€™")

    if len(stable_df) == 0:
        st.info(
            "í˜„ì¬ íŒŒë¼ë¯¸í„°ì—ì„œëŠ” ê¸°ì¤€ ì„¤ì • ì‹œì ì˜ Top-Nê³¼ ê²¹ì¹˜ëŠ” ì˜ì‹¬ ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤. "
            "ì˜¤ì—¼ ë¹„ìœ¨Â·ê°€ì¤‘ì¹˜ë¥¼ ì¡°ê¸ˆ ì¡°ì •í•´ë³´ì„¸ìš”."
        )
    else:
        st.caption(
            "â€» ê¸°ì¤€: ì—…ë¡œë“œ ë‹¹ì‹œ **ê¸°ë³¸ ì„¤ì •(ì˜¤ì—¼ë¹„ìœ¨ 0.10, ê°€ì¤‘ì¹˜ 1:1:1)** ë¡œ ê³„ì‚°í•œ Top-Nê³¼, "
            "í˜„ì¬ ì„¤ì • Top-Nì— ëª¨ë‘ í¬í•¨ëœ ê¸°ì—…/ì—°ë„ ì¡°í•©ì…ë‹ˆë‹¤."
        )
        st.dataframe(
            stable_df[show_cols],
            use_container_width=True,
            height=260,
        )

with tab2:
    st.subheader("ë™ì¢… ê·¸ë£¹ ì—´ì§€ë„ (ë¹„ìŠ·í•œ íšŒì‚¬ë¼ë¦¬ ì§€í‘œ ë¹„êµ)")

    if df_scored.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        years = sorted(df_scored["year"].dropna().unique())
        sel_year = st.selectbox("ì—°ë„ ì„ íƒ", years, key="peer_year")

        industries = sorted(df_scored["industry"].dropna().unique())
        sel_ind = st.selectbox("ì‚°ì—… ì„ íƒ", industries, key="peer_ind")

        subset = df_scored[
            (df_scored["year"] == sel_year) & (df_scored["industry"] == sel_ind)
        ].copy()

        if subset.empty:
            st.warning("í•´ë‹¹ ì—°ë„Â·ì‚°ì—… ì¡°í•©ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            companies = subset["company"].unique().tolist()
            sel_comp = st.selectbox("ê¸°ì¤€ íšŒì‚¬ ì„ íƒ", companies, key="peer_comp")

            focus = subset[subset["company"] == sel_comp].copy()
            if focus.empty:
                st.warning("ì„ íƒí•œ íšŒì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                eps = 1e-9
                subset["size_metric"] = np.log1p(subset["total_assets"])
                subset["growth_metric"] = subset["sales_yoy"].fillna(0.0)
                subset["profit_metric"] = (
                    subset["net_income"] / (subset["sales"] + eps)
                ).replace([np.inf, -np.inf], np.nan).fillna(0.0)

                for c in ["size_metric", "growth_metric", "profit_metric"]:
                    m = subset[c].mean()
                    s = subset[c].std(ddof=0) or eps
                    subset[c + "_z"] = (subset[c] - m) / s

                focus = subset[subset["company"] == sel_comp].copy()
                focus_row = focus.iloc[0]

                f_vec = np.array(
                    [
                        float(focus_row["size_metric_z"]),
                        float(focus_row["growth_metric_z"]),
                        float(focus_row["profit_metric_z"]),
                    ]
                )

                subset["peer_dist"] = subset.apply(
                    lambda r: np.linalg.norm(
                        np.array(
                            [
                                r["size_metric_z"],
                                r["growth_metric_z"],
                                r["profit_metric_z"],
                            ]
                        )
                        - f_vec
                    ),
                    axis=1,
                )

                k = st.slider(
                    "ë™ì¢… ê·¸ë£¹ í¬ê¸° (ê¸°ì¤€ íšŒì‚¬ í¬í•¨)",
                    min_value=3,
                    max_value=min(10, subset.shape[0]),
                    value=min(5, subset.shape[0]),
                )

                peer = subset.nsmallest(k, "peer_dist").copy()

                st.caption(
                    "â€» ê°™ì€ ì—°ë„Â·ì‚°ì—… ë‚´ì—ì„œ ìì‚° ê·œëª¨, ë§¤ì¶œ ì„±ì¥ë¥ , ì´ìµë¥ ì´ ë¹„ìŠ·í•œ íšŒì‚¬ë¥¼ ë™ì¢… ê·¸ë£¹ìœ¼ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤."
                )

                metrics = [
                    "ar_to_sales",
                    "inv_to_sales",
                    "tata",
                    "ocf_to_ni",
                    "mscore_raw",
                    "iso_score",
                ]
                metrics = [m for m in metrics if m in peer.columns]

                if len(metrics) == 0:
                    st.info("ì—´ì§€ë„ë¡œ ë³´ì—¬ì¤„ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    peer_z = peer.copy()
                    for m in metrics:
                        col_name = str(m)
                        mm = peer[col_name].mean()
                        ss = peer[col_name].std(ddof=0) or 1e-9
                        peer_z[col_name + "_z_peer"] = (peer[col_name] - mm) / ss

                    z_cols = [str(m) + "_z_peer" for m in metrics]
                    z_vals = peer_z[z_cols].values
                    labels = [
                        f"{r['company']}_{int(r['year'])}"
                        for _, r in peer.iterrows()
                    ]

                    fig, ax = plt.subplots(
                        figsize=(1.2 * len(metrics), 0.5 * len(peer) + 1)
                    )
                    im = ax.imshow(z_vals, aspect="auto", cmap="coolwarm")

                    ax.set_xticks(np.arange(len(metrics)))
                    ax.set_xticklabels(metrics, rotation=45, ha="right")
                    ax.set_yticks(np.arange(len(labels)))
                    ax.set_yticklabels(labels)

                    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
                    ax.set_title("ë™ì¢… ê·¸ë£¹ ë‚´ ì§€í‘œ í¸ì°¨ (z-score)")
                    st.pyplot(fig)

                    st.caption(
                        "ìƒ‰ì´ ë¶‰ì„ìˆ˜ë¡ ë™ì¢… í‰ê· ë³´ë‹¤ ë†’ê³ , í‘¸ë¥¼ìˆ˜ë¡ ë‚®ìŠµë‹ˆë‹¤."
                    )

with tab3:
    st.subheader("Benford ë²•ì¹™ ì‚¬ìš© ê°€ëŠ¥ì„± ì§„ë‹¨")

    ben_ok = meta.get("benford_applicable", False)
    reason = meta.get("benford_reason", "")
    dist = meta.get("benford_overall", {})

    if ben_ok:
        st.success(
            f"ì´ ë°ì´í„° ì§‘í•©ì€ Benford ë²•ì¹™ì„ ì ìš©í•˜ê¸°ì— ëŒ€ì²´ë¡œ ì ì ˆí•©ë‹ˆë‹¤. "
            f"(í‘œë³¸ ìˆ˜ n={meta.get('benford_n')}, "
            f"ìµœëŒ€/ìµœì†Œ ë¹„ìœ¨â‰ˆ{meta.get('benford_span'):.1f})"
        )
    else:
        st.warning(
            "âš ï¸ í•´ë‹¹ ë°ì´í„°ëŠ” Benford ë²•ì¹™ì„ ì ìš©í•˜ê¸°ì— ì ì ˆí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
            f"ì‚¬ìœ : {reason}"
        )

    if dist:
        obs = dist.get("obs")
        exp = dist.get("exp")
        if obs is not None and exp is not None and len(obs) == 9:
            digits = np.arange(1, 10)
            width = 0.35

            fig, ax = plt.subplots()
            ax.bar(digits - width / 2, exp, width, label="ì´ë¡ (ë² ë‹ˆí¬ë“œ)")
            ax.bar(digits + width / 2, obs, width, label="ì‹¤ì œ(ë§¤ì¶œ)")
            ax.set_xticks(digits)
            ax.set_xlabel("ì„ ë‘ ìë¦¿ìˆ˜")
            ax.set_ylabel("ë¹„ìœ¨")
            ax.set_title(
                f"ì„ ë‘ ìë¦¿ìˆ˜ ë¶„í¬ ë¹„êµ (MAD={dist.get('mad', np.nan):.4f})"
            )
            ax.legend()
            st.pyplot(fig)

            st.caption(
                "â€» ê·¸ë˜í”„ëŠ” ì „ì²´ ë§¤ì¶œ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ëª¨ì•„, ì„ ë‘ ìˆ«ì ë¶„í¬ê°€ "
                "ì´ë¡ ì  Benford ë¶„í¬ì™€ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. "
                "í‘œë³¸ ìˆ˜ê°€ ì ê±°ë‚˜ ê¸ˆì•¡ ë²”ìœ„ê°€ ì¢ìœ¼ë©´ ì‹ ë¢°ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        else:
            st.info("Benford ë¶„í¬ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    st.markdown("---")
    st.markdown(
        f"Benford ê²°ê³¼ê°€ ìµœì¢… ì ìˆ˜ì— ì‹¤ì œ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€: "
        f"**{'ì˜ˆ' if meta.get('benford_used_in_score') else 'ì•„ë‹ˆì˜¤(ê°€ì¤‘ì¹˜ 0ìœ¼ë¡œ ì²˜ë¦¬)' }**"
    )
